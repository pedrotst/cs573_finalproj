{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9c9e27-a02b-44ce-84d2-202ba110c0c8",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b19698-cca9-40e3-ab71-876ea1ccc367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy206/.conda/envs/cent7/2020.11-py38/NWRGAE/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import utils\n",
    "# import models\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from gan import *\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "    \n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import models\n",
    "import utils\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import seaborn as sns  # For visualizing the confusion matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "import pdb\n",
    "\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import models\n",
    "import utils\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import seaborn as sns  # For visualizing the confusion matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13809c8-d206-4303-a42a-46f3b1bc6f47",
   "metadata": {},
   "source": [
    "# Models (28 x 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61da64d7-fa82-4aec-bb6b-cae5744c7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Generator, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.architecture = self.opt.architecture\n",
    "\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        modules = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(opt.n_paths_G):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                *block(opt.latent_dim,2,normalize=False),\n",
    "                *block(2,128),\n",
    "                *block(128,256),\n",
    "                *block(256,512),\n",
    "                *block(512,1024),\n",
    "                nn.Linear(1024, int(np.prod(opt.img_shape))),\n",
    "                nn.Tanh()\n",
    "            ))\n",
    "        self.paths = modules\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = []\n",
    "        for path in self.paths:\n",
    "            img.append(path(z).view(img.size(0), *self.opt.img_shape))\n",
    "        img = torch.cat(img, dim=0)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(int(np.prod(opt.img_shape)), 512)\n",
    "        self.lr1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.lr2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        encoder_layers = []\n",
    "\n",
    "        encoder_layers += [self.fc1]\n",
    "        encoder_layers += [self.lr1]\n",
    "        encoder_layers += [self.fc2]\n",
    "        encoder_layers += [self.lr2]\n",
    "        \n",
    "        self.encoder_layers = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        modules = nn.ModuleList()\n",
    "        \n",
    "        modules.append(nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "                ))\n",
    "        modules.append(nn.Sequential(\n",
    "            nn.Linear(256, opt.n_paths_G),\n",
    "                ))\n",
    "        self.paths = modules\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        # img_flat = self.lr2(self.fc2(self.lr1(self.fc1(img_flat))))\n",
    "        img_flat = self.encoder_layers(img_flat)\n",
    "        \n",
    "        validity = self.paths[0](img_flat)\n",
    "        classifier = F.log_softmax(self.paths[1](img_flat), dim=1)\n",
    "        \n",
    "        return validity, classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8764a1-f8cd-4aad-bfff-66cf3fb6e2c3",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c16c1f-068a-42a5-bd90-6e51333c395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clustering_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the clustering accuracy for the case where the number of clusters\n",
    "    might be different from the number of true classes. It uses the Hungarian algorithm.\n",
    "\n",
    "    Args:\n",
    "    y_true (array-like): True labels.\n",
    "    y_pred (array-like): Predicted cluster labels.\n",
    "\n",
    "    Returns:\n",
    "    float: Clustering accuracy.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    return sum([w[row, col] for row, col in zip(row_ind, col_ind)]) / y_pred.size\n",
    "\n",
    "\n",
    "def get_cluster(dataloader, discriminator, soft_preds=False, noise_intensity=0):\n",
    "    #cuda = True if torch.cuda.is_available() else False\n",
    "    #Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    all_data = []\n",
    "    all_idxs = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x,y) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            x = add_noise(x, noise_intensity)\n",
    "            y = y.to(device)\n",
    "            d_out, c_out = discriminator(x)\n",
    "            all_preds.append(c_out)\n",
    "            all_idxs.append(y)\n",
    "    all_idxs = torch.cat(all_idxs, axis=0)\n",
    "    all_preds = torch.cat(all_preds, axis=0)\n",
    "    if soft_preds:\n",
    "        return all_idxs, all_preds\n",
    "    else:\n",
    "        return all_idxs, torch.argmax(all_preds, dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    \n",
    "\n",
    "def add_noise(tensor, normal_std_scale):\n",
    "    if (normal_std_scale > 0):\n",
    "        return tensor + (tensor*torch.randn_like(tensor)*normal_std_scale)\n",
    "    else:\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ef6ff-5f6e-46ea-87af-61f96f236850",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93bd101b-ed07-4527-94cd-557f647e99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(opt):\n",
    "    generator = models.Generator(opt)\n",
    "    discriminator = models.Discriminator(opt)\n",
    "    img_shape = opt.img_shape\n",
    "\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "    if cuda:\n",
    "        generator.cuda()\n",
    "        discriminator.cuda()\n",
    "        adversarial_loss.cuda()\n",
    "\n",
    "    # Configure data loader\n",
    "    os.makedirs(\"data/fmnist\", exist_ok=True)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(\n",
    "            \"data/fmnist\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=opt.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "    for epoch in range(opt.n_epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "        \n",
    "        epoch_start = 0\n",
    "        \n",
    "        g_loss_epoch = 0\n",
    "        d_loss_epoch = 0\n",
    "        c_loss_1_epoch = 0\n",
    "        c_loss_2_epoch = 0\n",
    "        \n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            \n",
    "            valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "            real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "            # -----------------------------------------------------\n",
    "            #  Train Generator \n",
    "            # -----------------------------------------------------\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (opt.batch_size_g, opt.latent_dim))))\n",
    "            g_loss = 0 \n",
    "            c_loss_1 = 0 \n",
    "            \n",
    "            for k in range(opt.n_paths_G):\n",
    "\n",
    "                gen_imgs = generator.paths[k](z)\n",
    "                validity, classifier = discriminator(gen_imgs)\n",
    "                g_loss += adversarial_loss(validity, valid)\n",
    "\n",
    "                target = Variable(Tensor(imgs.size(0)).fill_(k), requires_grad=False)\n",
    "                target = target.type(torch.cuda.LongTensor)\n",
    "                \n",
    "                c_loss_1 += F.nll_loss(classifier, target) * opt.classifier_para_g\n",
    "\n",
    "                _, predicted = torch.max(classifier.data, 1)\n",
    "                total_predictions += target.size(0)\n",
    "                correct_predictions += (predicted == target).sum().item()\n",
    "        \n",
    "                # Collect all targets and predictions for confusion matrix\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            g_loss_epoch += g_loss\n",
    "            c_loss_1_epoch += c_loss_1       \n",
    "            g_loss = g_loss + c_loss_1\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # ------------------------------------------------------------------------\n",
    "            #  Train Discriminator and Classifier (WE CALL THIS STAGE PHASE 2)\n",
    "            # ------------------------------------------------------------------------\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            d_loss = 0 #adversarial loss for discrimination to be applied to the discriminator\n",
    "            c_loss_2 = 0 #classification loss to be applied to the classifier\n",
    "            \n",
    "            #loss of the discriminator with real images\n",
    "            validity, classifier = discriminator(real_imgs)\n",
    "            real_loss = adversarial_loss(validity, valid)\n",
    "            \n",
    "            temp = [] #variable to store images for plot\n",
    "            \n",
    "            #again we iterate over each of the generators\n",
    "            for k in range(opt.n_paths_G):\n",
    "\n",
    "                # generates a batch of images with generator k\n",
    "                gen_imgs = generator.paths[k](z).view(imgs.shape[0], *img_shape)\n",
    "                temp.append(gen_imgs[0:10, :])\n",
    "\n",
    "                #again we measure the outputs of the discriminator and the classifier \n",
    "                validity, classifier = discriminator(gen_imgs.detach())\n",
    "                \n",
    "                #loss of the discriminator with fake images\n",
    "                fake_loss = adversarial_loss(validity, fake)\n",
    "                \n",
    "                #sums up the fake and true losses\n",
    "                d_loss += (real_loss + fake_loss) / 2\n",
    "\n",
    "                #again we calculate the loss of the classifier. Note that it is calculated...\n",
    "                #...in exactly the same way as before, but only after the...\n",
    "                #...generator has already had its weights updated in PHASE 1.\n",
    "                #reminder: opt.classifier_para is just a multiplicative constant of the loss\n",
    "                target = Variable(Tensor(imgs.size(0)).fill_(k), requires_grad=False)\n",
    "                target = target.type(torch.cuda.LongTensor)\n",
    "                c_loss_2 += F.nll_loss(classifier, target) * opt.classifier_para\n",
    "            \n",
    "            #images for plot\n",
    "            plot_imgs = torch.cat(temp, dim=0)\n",
    "\n",
    "            #again, we accumulate the losses to visualize the total for the epoch\n",
    "            d_loss_epoch += d_loss\n",
    "            c_loss_2_epoch += c_loss_2\n",
    "            \n",
    "            #we add both losses into the same variable \n",
    "            d_loss = d_loss + c_loss_2\n",
    "            #jointly apply the gradients to the layers of the discriminator and classifier\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "        \n",
    "        #printing training information\n",
    "        interval = time.time() - start\n",
    "        \n",
    "        if (epoch < 20 and epoch % 5 == 0) or (epoch > 20 and epoch % 20 == 0):\n",
    "            \n",
    "            # print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [C loss 1: %f] [C loss 2: %f] \\t Time Interv: %f\"\n",
    "            #        % (epoch, opt.n_epochs, i, num_batches, d_loss_epoch.item()/num_batches, g_loss_epoch.item()/num_batches, \n",
    "            #           c_loss_1_epoch.item()/num_batches, c_loss_2_epoch.item()/num_batches, interval))\n",
    "\n",
    "            classification_accuracy = 100.0 * correct_predictions / total_predictions\n",
    "\n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [C loss 1: %f] [C loss 2: %f] [Acc: %.2f%%] \\t Time Interv: %f\"\n",
    "                % (epoch, opt.n_epochs, i, num_batches, d_loss_epoch.item()/num_batches, g_loss_epoch.item()/num_batches, \n",
    "                    c_loss_1_epoch.item()/num_batches, c_loss_2_epoch.item()/num_batches, classification_accuracy, interval))\n",
    "\n",
    "            utils.show(make_grid(plot_imgs[:opt.n_paths_G*10].cpu(), nrow=10, normalize=True), opt)\n",
    "            plt.show()\n",
    "            \n",
    "            # Compute and print confusion matrix at the end of each epoch\n",
    "            cm = confusion_matrix(all_targets, all_predictions)/(opt.batch_size_g*len(dataloader))\n",
    "            cm_rounded = np.around(cm, decimals=2)\n",
    "            fig, ax = plt.subplots(figsize=(opt.n_paths_G//2, opt.n_paths_G//2))\n",
    "            # sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues')\n",
    "            sns.heatmap(cm_rounded, annot=True, fmt=\".2f\", linewidths=.5, square = True, cmap = 'viridis')\n",
    "            ax.set_xlabel('Predicted Labels')\n",
    "            ax.set_ylabel('True Labels')\n",
    "            ax.set_title('Confusion Matrix')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d287359-bbed-47ee-90a7-33b9b703beb4",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c5a400-153e-4648-a21c-65bcaabe68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_args():\n",
    "\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # parser.add_argument('-f')\n",
    "    parser.add_argument('--n_epochs', type=int, default=500, help='number of epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=100, help='batch size')\n",
    "    parser.add_argument('--batch_size_g', type=int, default=100, help='generator batch size')\n",
    "    parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum')\n",
    "    parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of second order momentum')\n",
    "    parser.add_argument('--n_cpu', type=int, default=12, help='number of cpu threads to use during batch generation')\n",
    "    parser.add_argument('--latent_dim', type=int, default=100, help='dimensionality of the latent space')\n",
    "    parser.add_argument('--sample_interval', type=int, default=1, help='interval between image samples')\n",
    "    parser.add_argument('--classifier_para', type=float, default=1.0, help='classifier loss weight')\n",
    "    parser.add_argument('--classifier_para_g', type=float, default=1.0, help=\"generator's classification loss weight\")\n",
    "    parser.add_argument('--dataset', type=str, default='fmnist', help='dataset name') #choices=['fmnist', 'mnist', 'cifar10']\n",
    "    parser.add_argument('--architecture', default='mlp', help='architecture for the model')\n",
    "    parser.add_argument('--logs_path', default='logs_40', help='where to save logs')\n",
    "    parser.add_argument('--init_noise', type=float, default=1.0, help='Initial stdd of gaussian noise applied to input of discriminator')\n",
    "    parser.add_argument('--noise_decay', type=float, default=0.01, help='How much is subtracted of of gaussian stdd noise at each epoch')\n",
    "    \n",
    "    #generator parameters\n",
    "    parser.add_argument('--n_paths_G', type=int, default=40, help='number of generators')\n",
    "    parser.add_argument('--lr_g', type=float, default=0.001, help='learning rate for gen')\n",
    "    \n",
    "    parser.add_argument('--nf_g', type=int, default=128,help='Number of feature maps for generator.')\n",
    "    # parser.add_argument('--norm_g', type=str, default='layer_norm', choices=['layer_norm', 'batch_norm', 'no_norm'], help='Type of normalization layer used for generator')\n",
    "    parser.add_argument('--no_conv_g', type=int, default=2, choices=[2], help='Number of conv layers for gen')\n",
    "    \n",
    "    #discriminator/classifier parameters\n",
    "    parser.add_argument('--lr_d', type=float, default=0.001, help='learning rate for disc')\n",
    "    parser.add_argument('--lr_c', type=float, default=0.001, help='learning rate for clasf')\n",
    "    parser.add_argument('--nf_d', type=int, default=128, help='Number of feature maps for discriminator.')\n",
    "    parser.add_argument('--norm_d', type=str, default='layer_norm', choices=['layer_norm', 'batch_norm', 'no_norm'], help='Type of normalization layer used for discriminator')\n",
    "    parser.add_argument('--no_conv_d', type=int, default=3, choices=[3], help='Number of conv layers for discriminator')\n",
    "    \n",
    "    \n",
    "    parser.set_defaults(shared_features_across_ref=False)\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.dataset == 'cifar10':\n",
    "        args.img_size = 32\n",
    "        args.channels = 3\n",
    "    else:  \n",
    "        args.img_size = 28\n",
    "        args.channels = 1\n",
    "\n",
    "    args.img_shape = (args.channels, args.img_size, args.img_size)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def show(img, opt):\n",
    "    npimg = img.detach().numpy()\n",
    "    dim = max(5, opt.n_paths_G//2)\n",
    "    plt.figure(figsize = (dim, dim))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd60bfe-3403-4918-8534-6d1f47bf84d5",
   "metadata": {},
   "source": [
    "# Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6901b-362f-43b4-b512-6a66728b5061",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/500] [D loss: 26.325101] [G loss: 31.987572] [C loss 1: 8.523518] [C loss 2: 8.502166] [Acc: 98.43%] \t Time Interv: 329.632448\n",
      "Clustering metrics:\n",
      "NMI:0.368485329766552\n",
      "ACC:0.2737833333333333\n",
      "40\n",
      "[0.368485329766552, 0.3542245778394509, 0.3523124675732253, 0.3497701384699673, 0.3411890106629037, 0.3415256559494391, 0.341873393048393, 0.32503942782046086, 0.31466374018098575, 0.30976744037273507, 0.3094598608608991, 0.3071156225828966, 0.3052425779211719, 0.28674951207779853, 0.28068496773707896, 0.28019833126607513, 0.27502546339771444, 0.26667686041914856, 0.26697114231554603, 0.2346939846252207, 0.21004930101029548, 0.19835477091476922, 0.19562657111650042, 0.1952577245015422, 0.18899913066706006, 0.1729177188351592, 0.16955726466346321, 0.16035646458438693, 0.11014564105506795, 0.10507043726275217, 0.10101401688702842]\n",
      "[0.2737833333333333, 0.27386666666666665, 0.2739, 0.2874, 0.2817, 0.2817, 0.2894833333333333, 0.26005, 0.26005, 0.2601, 0.26011666666666666, 0.26011666666666666, 0.2601333333333333, 0.2557833333333333, 0.2559, 0.25801666666666667, 0.2585166666666667, 0.25931666666666664, 0.2618666666666667, 0.25715, 0.24055, 0.22541666666666665, 0.2276, 0.22765, 0.2255, 0.21398333333333333, 0.21398333333333333, 0.2062, 0.17133333333333334, 0.17163333333333333, 0.1679]\n",
      "[Epoch 1/500] [D loss: 28.301302] [G loss: 28.679144] [C loss 1: 1.041654] [C loss 2: 1.060006] [Acc: 99.96%] \t Time Interv: 338.186498\n",
      "Clustering metrics:\n",
      "NMI:0.4066020544727988\n",
      "ACC:0.2542333333333333\n",
      "40\n",
      "[0.40660205447279885, 0.39730459915310434, 0.3932802201990493, 0.3962623778465954, 0.37993516308079217, 0.38143387164045334, 0.38128936092845384, 0.36160652448118275, 0.3481575977393096, 0.3323299547791308, 0.3243894957733368, 0.32044791033054093, 0.31118329453983434, 0.3120332381188809, 0.30693236090323944, 0.3068550168637662, 0.30660438276229207, 0.28875933193569403, 0.27411939299147875, 0.2516353836284785, 0.2395794124922108, 0.21550608974198657, 0.21419431884470205, 0.21358167140607748, 0.20270950645056035, 0.1913381159941335, 0.1845125934830366, 0.17851411281706034, 0.17227439716457138, 0.17033260596605512, 0.16669202493597454]\n",
      "[0.2542333333333333, 0.2542333333333333, 0.2548166666666667, 0.2627833333333333, 0.2627833333333333, 0.26721666666666666, 0.29178333333333334, 0.29183333333333333, 0.29183333333333333, 0.2740666666666667, 0.27408333333333335, 0.28155, 0.2796, 0.28025, 0.28026666666666666, 0.28413333333333335, 0.285, 0.285, 0.27545, 0.25576666666666664, 0.2485, 0.22806666666666667, 0.22213333333333332, 0.22536666666666666, 0.21971666666666667, 0.21208333333333335, 0.20935, 0.20438333333333333, 0.20196666666666666, 0.2007, 0.19416666666666665]\n",
      "[Epoch 2/500] [D loss: 28.450544] [G loss: 28.239183] [C loss 1: 0.537716] [C loss 2: 0.545483] [Acc: 99.95%] \t Time Interv: 330.233559\n",
      "Clustering metrics:\n",
      "NMI:0.4257989416827713\n",
      "ACC:0.24956666666666666\n",
      "40\n",
      "[0.42579894168277144, 0.41684948526301885, 0.4079190569690126, 0.40846291743268553, 0.3969522263309903, 0.398652097276476, 0.39887416470421266, 0.3778912197575898, 0.3656370540969546, 0.3539686327617706, 0.3426392145090056, 0.3356190893868083, 0.3282100529389075, 0.3265751182070777, 0.3254298498019645, 0.3238210531653366, 0.3232310852193384, 0.30636289218131735, 0.28092439905643296, 0.2621774088944081, 0.25429775335935106, 0.22935185462517144, 0.2232741758773488, 0.22151442007774136, 0.20713716634029142, 0.20150101417442992, 0.19299876336113037, 0.1788654356702589, 0.1709331489654727, 0.16576344399149776, 0.16181007184428972]\n",
      "[0.24956666666666666, 0.25005, 0.2508166666666667, 0.25858333333333333, 0.25858333333333333, 0.26413333333333333, 0.2790666666666667, 0.27921666666666667, 0.27831666666666666, 0.2771166666666667, 0.2708, 0.2688, 0.2688833333333333, 0.2690666666666667, 0.26908333333333334, 0.2746166666666667, 0.27585, 0.27585, 0.2673333333333333, 0.2434, 0.2434, 0.2342, 0.2221, 0.22803333333333334, 0.22065, 0.21623333333333333, 0.21408333333333332, 0.19928333333333334, 0.19835, 0.19596666666666668, 0.18906666666666666]\n",
      "[Epoch 3/500] [D loss: 28.413050] [G loss: 28.190931] [C loss 1: 0.327944] [C loss 2: 0.335068] [Acc: 99.96%] \t Time Interv: 333.814582\n",
      "Clustering metrics:\n",
      "NMI:0.43182416242947536\n",
      "ACC:0.23681666666666668\n",
      "40\n",
      "[0.4318241624294754, 0.42226679317955235, 0.4113043928454869, 0.4118644821691339, 0.4009496549043376, 0.40293208388307783, 0.40268164651922506, 0.3838239092226533, 0.3713796506032944, 0.36283248814975316, 0.350125935398021, 0.3416983370699259, 0.3344198460130558, 0.3314650352000217, 0.3294398060636081, 0.3276813052227026, 0.3272426263725874, 0.3113038948919583, 0.2939758871275806, 0.2744124182868284, 0.26689329386388466, 0.2407441769061991, 0.23643744435609299, 0.23460639006573697, 0.21935011628042267, 0.21431781653618168, 0.2062340263816179, 0.19119869526711397, 0.17923464853707882, 0.17089512643352844, 0.16687609750430216]\n",
      "[0.23681666666666668, 0.23681666666666668, 0.23691666666666666, 0.24396666666666667, 0.24396666666666667, 0.25046666666666667, 0.26736666666666664, 0.2674, 0.26725, 0.26721666666666666, 0.2669666666666667, 0.2669666666666667, 0.26713333333333333, 0.26713333333333333, 0.26715, 0.2717, 0.27295, 0.27295, 0.27908333333333335, 0.25356666666666666, 0.2548, 0.24648333333333333, 0.2408, 0.24675, 0.23468333333333333, 0.23255, 0.23266666666666666, 0.21658333333333332, 0.20698333333333332, 0.19865, 0.19271666666666668]\n",
      "[Epoch 4/500] [D loss: 28.302669] [G loss: 28.162406] [C loss 1: 0.236769] [C loss 2: 0.243234] [Acc: 99.97%] \t Time Interv: 330.798154\n",
      "Clustering metrics:\n",
      "NMI:0.4369328783614946\n",
      "ACC:0.22391666666666668\n",
      "40\n",
      "[0.4369328783614946, 0.4272754310868607, 0.41599716350117644, 0.41706002835239814, 0.407772999824981, 0.4095464591677383, 0.40962644139826754, 0.3900032039552628, 0.3793510142783101, 0.3712665457975923, 0.35813322051294566, 0.34645911303024124, 0.3374372963241161, 0.3339767857029552, 0.33127579359181, 0.3296006605998379, 0.32912723534216287, 0.3115482086039974, 0.2960947522174856, 0.28207025654134144, 0.27455002907375736, 0.24996519167675446, 0.24642279304099138, 0.24275775070568023, 0.22985877911749542, 0.2260339951454245, 0.2157406091899366, 0.2020399965620092, 0.18925575592027338, 0.17807150713449188, 0.1738826084289268]\n",
      "[0.22391666666666668, 0.22391666666666668, 0.22401666666666667, 0.22921666666666668, 0.22921666666666668, 0.23398333333333332, 0.25206666666666666, 0.2520833333333333, 0.25216666666666665, 0.2511333333333333, 0.2511833333333333, 0.2511833333333333, 0.25135, 0.25135, 0.2513666666666667, 0.25775, 0.25866666666666666, 0.25651666666666667, 0.265, 0.24508333333333332, 0.24698333333333333, 0.239, 0.23858333333333334, 0.24413333333333334, 0.23781666666666668, 0.23728333333333335, 0.23736666666666667, 0.22298333333333334, 0.21205, 0.19905, 0.19216666666666668]\n",
      "[Epoch 5/500] [D loss: 28.230931] [G loss: 28.221286] [C loss 1: 0.186849] [C loss 2: 0.194076] [Acc: 99.97%] \t Time Interv: 330.205969\n",
      "Clustering metrics:\n",
      "NMI:0.449042257297388\n",
      "ACC:0.22458333333333333\n",
      "40\n",
      "[0.449042257297388, 0.4394448398408246, 0.4288733219941499, 0.429563806556596, 0.4178596756284244, 0.41870328325006567, 0.4186658861336671, 0.39796004029676824, 0.38849693221011955, 0.38027491398471613, 0.3665227649847478, 0.353122337522792, 0.34534738598660036, 0.3434009266548592, 0.34040749890168365, 0.3369840859973247, 0.3364036277407245, 0.32104712993769036, 0.3013447326750243, 0.28771189224021937, 0.2828013271965408, 0.26139026951319366, 0.2602358151417713, 0.2525300113527333, 0.24009880018789628, 0.235732090860176, 0.22712222870942805, 0.21249828318384445, 0.19826215376617318, 0.1857119044545419, 0.18221463909410057]\n",
      "[0.22458333333333333, 0.22505, 0.22515, 0.22668333333333332, 0.22743333333333332, 0.23036666666666666, 0.24845, 0.24778333333333333, 0.2482, 0.24891666666666667, 0.249, 0.24926666666666666, 0.24928333333333333, 0.24935, 0.24935, 0.25825, 0.25883333333333336, 0.25883333333333336, 0.27086666666666664, 0.25333333333333335, 0.25333333333333335, 0.24826666666666666, 0.24948333333333333, 0.25325, 0.25025, 0.24533333333333332, 0.2454, 0.23006666666666667, 0.21721666666666667, 0.20246666666666666, 0.19648333333333334]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "def main():\n",
    "    # opt = utils.arg_parser_subst(sys.argv)\n",
    "    opt = utils.parse_args()\n",
    "    opt.dataset = \"fmnist\"\n",
    "    opt.logs_path = \"logs_path_40\"\n",
    "    opt.n_paths_G = 40\n",
    "    # print(opt.dataset)\n",
    "\n",
    "    if opt.dataset == \"fmnist\":\n",
    "        os.makedirs(\"data/fmnist\", exist_ok=True)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST(\n",
    "                \"data/fmnist\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=transforms.Compose(\n",
    "                    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "                ),\n",
    "            ),\n",
    "            batch_size=opt.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        if(\"cnn\" in opt.architecture):\n",
    "            import models_cnn_28 as models\n",
    "        else:\n",
    "            import models\n",
    "        \n",
    "\n",
    "    if opt.dataset == \"mnist\":\n",
    "        os.makedirs(\"data/mnist\", exist_ok=True)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"data/mnist\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=transforms.Compose(\n",
    "                    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "                ),\n",
    "            ),\n",
    "            batch_size=opt.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        if(\"cnn\" in opt.architecture):\n",
    "            import models_cnn_28 as models\n",
    "        else:\n",
    "            import models\n",
    "        \n",
    "        \n",
    "    elif opt.dataset == \"cifar10\":\n",
    "        os.makedirs(\"data/CIFAR10\", exist_ok=True)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            datasets.CIFAR10('data/CIFAR10', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize([.5],[.5])\n",
    "                   ])\n",
    "            ),\n",
    "            batch_size=opt.batch_size, \n",
    "            shuffle=True)\n",
    "        if(\"cnn\" in opt.architecture):\n",
    "            import models_cnn_32 as models\n",
    "        else:\n",
    "            import models\n",
    "\n",
    "    generator = Generator(opt) #ok \n",
    "    discriminator = Discriminator(opt) # ok\n",
    "    \n",
    "    # print(\"Generator: \", generator)\n",
    "    # print(\"Discriminator/classifier: \", discriminator)\n",
    "    \n",
    "    #optimizer G\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr_g, betas=(opt.b1, opt.b2))\n",
    "    \n",
    "    #optimizer D\n",
    "    optimizer_D = torch.optim.Adam(list(discriminator.encoder_layers.parameters()) + list(discriminator.paths[0].parameters()), lr=opt.lr_d, betas=(opt.b1, opt.b2))\n",
    "    # optimizer_D.add_param_group(discriminator.paths[0].parameters())\n",
    "    \n",
    "    #optimizer C\n",
    "    optimizer_C = torch.optim.Adam(discriminator.paths[1].parameters(), lr=opt.lr_c, betas=(opt.b1, opt.b2))\n",
    "    gan = Gan(generator, discriminator, optimizer_G, optimizer_D, optimizer_C, opt)\n",
    "\n",
    "    gan.train(dataloader)\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad64419-1149-413d-b629-ca0e283d42d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NWRGAE",
   "language": "python",
   "name": "nwrgae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
